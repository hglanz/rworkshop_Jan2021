<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
  <head>
    <title>Text Analysis in R</title>
    <meta charset="utf-8" />
    <meta name="author" content="Kelly Bodwin" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Text Analysis in R
## Day 3
### Kelly Bodwin

---






---
class: center, middle
# Regular Expressions

---
# Regular Expressions

A **regular expression** is a way of "fuzzy matching" text.



```r
my_str &lt;- c("Kelly", "Jelly", "Belly", "Smelly", "Hi Kelly", "Kelly Bodwin")

str_extract(my_str, "Kelly")
```



```
## [1] "Kelly" NA      NA      NA      "Kelly" "Kelly"
```



```r
str_extract(my_str, ".elly")
```



```
## [1] "Kelly" "Jelly" "Belly" "melly" "Kelly" "Kelly"
```



```r
str_extract(my_str, "[A-z]+elly")
```



```
## [1] "Kelly"  "Jelly"  "Belly"  "Smelly" "Kelly"  "Kelly"
```



---
# Regular Expressions

* Letters and numbers match themselves

* `.` matches any character at all

* "escape" a special character with `\\` to match the literal character

---
# Regular Expressions

* `^` matches the start of the string



```r
str_subset(my_str, "^Kelly")
```



```
## [1] "Kelly"        "Kelly Bodwin"
```



* `$` matches the end of the string



```r
str_subset(my_str, "Kelly$")
```



```
## [1] "Kelly"    "Hi Kelly"
```



---
# Regular Expressions

* `{2}` means "the thing before me, exactly twice.

* `+` means "the thing before me, 0 to infinity times."

* `*` means "the thing before me, 0 to infinity times."





```r
my_str &lt;- c("Key", "Kely", "Kelly", "Kellly", "Kelllllly")

str_subset(my_str, "l{2}")
```



```
## [1] "Kelly"     "Kellly"    "Kelllllly"
```



```r
str_subset(my_str, "l+")
```



```
## [1] "Kely"      "Kelly"     "Kellly"    "Kelllllly"
```



```r
str_subset(my_str, "l*")
```



```
## [1] "Key"       "Kely"      "Kelly"     "Kellly"    "Kelllllly"
```



---

# Regular Expressions

* `[:alpha:]` or `[A-z]` matches any letter
* `[:punct:]` matches any punctuation
* (many more of these - see `stringr` cheatsheet!)
* `()` groups things together
* `[]` is "match any of these"



```r
my_str &lt;- c("Kelly", "Kelkel")

str_subset(my_str, "([Kk]el){2}")
```



```
## [1] "Kelkel"
```



---
# Quick quiz

What will the following outputs be?



```r
my_str &lt;- "The Dursleys of Number 4 Privet Drive were 
happy to say that they were perfectly 
normal, thank you very much."

str_extract_all(my_str, ".*")

str_extract_all(my_str, "[:alpha:]+")

str_extract_all(my_str, "[:alpha:]*\\.")

str_extract_all(my_str, "[wv]er[ey]")

str_extract_all(my_str, "[:digit:] ([A-Z][a-z]*)+")
```



Bonus: What is the difference between `str_extract` and `str_extract_all`?

---

# Your Turn

The file `v_orig.txt` contains a monologue from the movie "V for Vendetta".  Read it into R as a string with:



```r
vspeech &lt;- readLines("./data/v_orig.txt")
```



```
## Warning in readLines("./data/v_orig.txt"): incomplete final line found on
## './data/v_orig.txt'
```



Answer the following:

* How many words are in this speech?  (Hint: `str_count`)
* How many words start with the letter "v"?
* How many sentences are in the speech?
* What is the longest word in the speech?
* (challenge) What is the only capitalized word that is not at the beginning of a sentence?

---
class: center, middle

# Tokenizing

&lt;img src="tidytext.png" width=300&gt;

---

# Converting text to data

We need to separate text into words and/or n-grams.  These are called **tokens**.

The package `tokenizers` makes this much easier.



```r
library(tokenizers)
```



```
## Warning: package 'tokenizers' was built under R version 3.6.1
```



```r
vspeech %&gt;%
  tokenize_words()
```



```
## [[1]]
##   [1] "voila"        "in"           "view"         "a"           
##   [5] "humble"       "vaudevillian" "veteran"      "cast"        
##   [9] "vicariously"  "as"           "both"         "victim"      
##  [13] "and"          "villain"      "by"           "the"         
##  [17] "vicissitudes" "of"           "fate"         "this"        
##  [21] "visage"       "no"           "mere"         "veneer"      
##  [25] "of"           "vanity"       "is"           "a"           
##  [29] "vestige"      "of"           "the"          "vox"         
##  [33] "populi"       "now"          "vacant"       "vanished"    
##  [37] "however"      "this"         "valorous"     "visitation"  
##  [41] "of"           "a"            "bygone"       "vexation"    
##  [45] "stands"       "vivified"     "and"          "has"         
##  [49] "vowed"        "to"           "vanquish"     "these"       
##  [53] "venal"        "and"          "virulent"     "vermin"      
##  [57] "van"          "guarding"     "vice"         "and"         
##  [61] "vouchsafing"  "the"          "violently"    "vicious"     
##  [65] "and"          "voracious"    "violation"    "of"          
##  [69] "volition"     "the"          "only"         "verdict"     
##  [73] "is"           "vengeance"    "a"            "vendetta"    
##  [77] "held"         "as"           "a"            "votive"      
##  [81] "not"          "in"           "vain"         "for"         
##  [85] "the"          "value"        "and"          "veracity"    
##  [89] "of"           "such"         "shall"        "one"         
##  [93] "day"          "vindicate"    "the"          "vigilant"    
##  [97] "and"          "the"          "virtuous"     "verily"      
## [101] "this"         "vichyssoise"  "of"           "verbiage"    
## [105] "veers"        "most"         "verbose"      "so"          
## [109] "let"          "me"           "simply"       "add"         
## [113] "that"         "it창"          "s"            "my"          
## [117] "very"         "good"         "honour"       "to"          
## [121] "meet"         "you"          "and"          "you"         
## [125] "may"          "call"         "me"           "v"
```



---



```r
vspeech %&gt;%
  tokenize_ngrams(3)
```



```
## [[1]]
##   [1] "voila in view"               "in view a"                  
##   [3] "view a humble"               "a humble vaudevillian"      
##   [5] "humble vaudevillian veteran" "vaudevillian veteran cast"  
##   [7] "veteran cast vicariously"    "cast vicariously as"        
##   [9] "vicariously as both"         "as both victim"             
##  [11] "both victim and"             "victim and villain"         
##  [13] "and villain by"              "villain by the"             
##  [15] "by the vicissitudes"         "the vicissitudes of"        
##  [17] "vicissitudes of fate"        "of fate this"               
##  [19] "fate this visage"            "this visage no"             
##  [21] "visage no mere"              "no mere veneer"             
##  [23] "mere veneer of"              "veneer of vanity"           
##  [25] "of vanity is"                "vanity is a"                
##  [27] "is a vestige"                "a vestige of"               
##  [29] "vestige of the"              "of the vox"                 
##  [31] "the vox populi"              "vox populi now"             
##  [33] "populi now vacant"           "now vacant vanished"        
##  [35] "vacant vanished however"     "vanished however this"      
##  [37] "however this valorous"       "this valorous visitation"   
##  [39] "valorous visitation of"      "visitation of a"            
##  [41] "of a bygone"                 "a bygone vexation"          
##  [43] "bygone vexation stands"      "vexation stands vivified"   
##  [45] "stands vivified and"         "vivified and has"           
##  [47] "and has vowed"               "has vowed to"               
##  [49] "vowed to vanquish"           "to vanquish these"          
##  [51] "vanquish these venal"        "these venal and"            
##  [53] "venal and virulent"          "and virulent vermin"        
##  [55] "virulent vermin van"         "vermin van guarding"        
##  [57] "van guarding vice"           "guarding vice and"          
##  [59] "vice and vouchsafing"        "and vouchsafing the"        
##  [61] "vouchsafing the violently"   "the violently vicious"      
##  [63] "violently vicious and"       "vicious and voracious"      
##  [65] "and voracious violation"     "voracious violation of"     
##  [67] "violation of volition"       "of volition the"            
##  [69] "volition the only"           "the only verdict"           
##  [71] "only verdict is"             "verdict is vengeance"       
##  [73] "is vengeance a"              "vengeance a vendetta"       
##  [75] "a vendetta held"             "vendetta held as"           
##  [77] "held as a"                   "as a votive"                
##  [79] "a votive not"                "votive not in"              
##  [81] "not in vain"                 "in vain for"                
##  [83] "vain for the"                "for the value"              
##  [85] "the value and"               "value and veracity"         
##  [87] "and veracity of"             "veracity of such"           
##  [89] "of such shall"               "such shall one"             
##  [91] "shall one day"               "one day vindicate"          
##  [93] "day vindicate the"           "vindicate the vigilant"     
##  [95] "the vigilant and"            "vigilant and the"           
##  [97] "and the virtuous"            "the virtuous verily"        
##  [99] "virtuous verily this"        "verily this vichyssoise"    
## [101] "this vichyssoise of"         "vichyssoise of verbiage"    
## [103] "of verbiage veers"           "verbiage veers most"        
## [105] "veers most verbose"          "most verbose so"            
## [107] "verbose so let"              "so let me"                  
## [109] "let me simply"               "me simply add"              
## [111] "simply add that"             "add that it창"               
## [113] "that it창 s"                  "it창 s my"                   
## [115] "s my very"                   "my very good"               
## [117] "very good honour"            "good honour to"             
## [119] "honour to meet"              "to meet you"                
## [121] "meet you and"                "you and you"                
## [123] "and you may"                 "you may call"               
## [125] "may call me"                 "call me v"
```



---

# Sentiment analysis

A popular approach to text analysis to to analyze *sentiments*, or how positive/negative certain language is.



```r
library(tidytext)
```



```
## Warning: package 'tidytext' was built under R version 3.6.1
```



```r
positive &lt;- get_sentiments("bing") %&gt;%
  filter(sentiment == "positive")

positive
```



```
## # A tibble: 2,005 x 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 abound      positive 
##  2 abounds     positive 
##  3 abundance   positive 
##  4 abundant    positive 
##  5 accessable  positive 
##  6 accessible  positive 
##  7 acclaim     positive 
##  8 acclaimed   positive 
##  9 acclamation positive 
## 10 accolade    positive 
## # ... with 1,995 more rows
```



---
# Sentiment analysis



```r
vdf &lt;- vspeech %&gt;%
  tokenize_words() %&gt;%
  data.frame()

names(vdf) &lt;- "word"
```



---
# Sentiment analysis



```r
vdf %&gt;%
  semi_join(positive) %&gt;%
  count(word, sort = TRUE)
```



```
## Joining, by = "word"
```



```
## Warning: Column `word` joining factor and character vector, coercing into
## character vector
```



```
## # A tibble: 4 x 2
##   word         n
##   &lt;fct&gt;    &lt;int&gt;
## 1 good         1
## 2 humble       1
## 3 vigilant     1
## 4 virtuous     1
```



---
# Try it

Find all the *negative* words in V's speech

---

# Word Clouds



```r
library(wordcloud)
```



```
## Warning: package 'wordcloud' was built under R version 3.6.1
```



```
vdf %&gt;%
  count(word) %&gt;%
  with(wordcloud(word, n, max.words = 100))
```

---

# Your Turn

The file `hamlet.txt` contains the entire text of the play "Hamlet".  Try one or two of the following:

* Make a wordcloud
* Determine which characters have the most lines in the play
* Find the most common positive and negative words
* Make a plot of sentiment by Act of the play
* Determine which characters speak most positively or negatively

Helpful links:
* [Regular Expression symbols](https://stat.ethz.ch/R-manual/R-devel/library/base/html/regex.html)
* [tidytext tutorial](https://cran.r-project.org/web/packages/tidytext/vignettes/tidytext.html)
* [stringr + regular expressions](https://stringr.tidyverse.org/articles/regular-expressions.html)
* [a fanastic book on Tidy Text!](https://www.tidytextmining.com/)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
